# Content Scraping Configuration
# Configuration for multi-source content acquisition and processing

scraping:
  youtube:
    api_key: "${AIzaSyCk4WC3d3sX6pTHQWu9otHwguZr1nEYSks}"
    max_transcript_length: 50000
    supported_languages: ["en", "es", "fr", "de", "it", "pt", "ru", "ja", "ko", "zh"]
    rate_limit: 100  # requests per day
    timeout: 30      # seconds
    
  general:
    max_file_size: "100MB"  # Default fallback limit
    supported_formats: ["pdf", "docx", "txt", "jpg", "png", "jpeg", "gif", "webp", "csv", "json", "epub", "zip", "tar", "gz"]
    rate_limit: 10  # requests per minute per domain
    timeout: 30     # seconds
    user_agent: "MCP-Yggdrasil/1.0 (Educational Research Bot)"
    
  file_size_limits:
    # Document files
    pdf: "200MB"      # Large academic collections, scanned documents
    docx: "100MB"     # Complex documents with embedded media
    doc: "100MB"      # Legacy Office documents
    txt: "50MB"       # Large text corpora
    md: "50MB"        # Extensive documentation
    rtf: "25MB"       # Rich text format
    epub: "100MB"     # Multimedia e-books
    
    # Image files
    jpg: "75MB"       # High-resolution scans
    jpeg: "75MB"      # High-resolution scans
    png: "75MB"       # Detailed diagrams, screenshots
    gif: "25MB"       # Educational animations
    webp: "50MB"      # Modern image format
    tiff: "100MB"     # High-quality scans
    
    # Data files
    csv: "100MB"      # Research datasets
    json: "50MB"      # Complex structured data
    xml: "50MB"       # Structured documents
    yaml: "10MB"      # Configuration files
    
    # Archive files
    zip: "500MB"      # Compressed document collections
    tar: "500MB"      # Archive collections
    gz: "500MB"       # Compressed archives
    rar: "500MB"      # Compressed archives
    
    # Specialized formats
    latex: "25MB"     # LaTeX documents
    bib: "10MB"       # Bibliography files
    log: "100MB"      # Log files for analysis
    
  web:
    respect_robots_txt: true
    max_page_size: "10MB"
    max_depth: 3
    concurrent_requests: 5
    delay_between_requests: 1  # seconds
    
  staging:
    max_pending_items: 1000
    auto_cleanup_days: 30
    analysis_timeout: 300  # seconds
    batch_size: 50
    
  ocr:
    engine: "tesseract"
    languages: ["eng", "spa", "fra", "deu"]
    confidence_threshold: 0.7
    
processing:
  domains:
    auto_classify: true
    confidence_threshold: 0.8
    default_domain: "general"
    
  quality:
    min_content_length: 100  # characters
    max_content_length: 1000000  # characters
    filter_duplicates: true
    content_similarity_threshold: 0.9
    
  analysis:
    default_agents: ["text_processor", "claim_analyzer"]
    max_agents_per_item: 5
    parallel_processing: true
    priority_levels: ["high", "medium", "low"]

monitoring:
  metrics:
    enabled: true
    collection_interval: 60  # seconds
    
  alerts:
    queue_size_threshold: 100
    error_rate_threshold: 0.1  # 10%
    processing_time_threshold: 600  # seconds
    
  logging:
    level: "INFO"
    format: "json"
    max_file_size: "100MB"
    backup_count: 5

security:
  content_filtering:
    enabled: true
    blocked_domains: []
    allowed_domains: []
    
  file_validation:
    scan_uploads: true
    max_scan_time: 30  # seconds
    
  rate_limiting:
    enabled: true
    per_ip_limit: 100  # requests per hour
    per_user_limit: 1000  # requests per day